# RAG Code Flow Documentation

## Overview
This document explains the complete data flow from when a user uploads a guideline file in the Streamlit UI to when that knowledge is retrieved from the vector database and used by the LLM for code review.

---

## ğŸ”„ Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          USER INTERACTION                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    User uploads guideline file (.md/.txt/.json)
                    User enters PR URL (e.g., github.com/owner/repo/pull/123)
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         UI.PY (Streamlit)                                â”‚
â”‚  Location: ui.py (lines 29-77)                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                               â–¼
        Parse PR URL                    Read Guideline File
     parse_github_pr_url()              guideline_file.getvalue()
     Returns:                           Decode to UTF-8 string
     - owner: "cuongnln0812"                â”‚
     - repo: "pullpal-ai-agent"             â”‚
     - pr_number: 123                       â”‚
                    â”‚                       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                    Create project_name = "owner/repo"
                    e.g., "cuongnln0812/pullpal-ai-agent"
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VECTOR STORE - STORAGE                                â”‚
â”‚  Location: agents/vector_store.py                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                store_project_guidelines(content, filename, project_name)
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                       â–¼
            Extract Owner           Chunk Text Content
            from project_name       _chunk_text(content, chunk_size=500)
            "cuongnln0812"          Splits by paragraphs (\\n\\n)
                    â”‚                       â”‚
                    â”‚               Chunks Example:
                    â”‚               - Chunk 0: "Use type hints..." (450 chars)
                    â”‚               - Chunk 1: "Follow PEP 8..." (380 chars)
                    â”‚               - Chunk 2: "Handle errors..." (420 chars)
                    â”‚                       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                    Build Metadata for each chunk
                    {
                      "filename": "coding_guidelines.md",
                      "project": "cuongnln0812/pullpal-ai-agent",
                      "owner": "cuongnln0812",
                      "chunk_index": 0,
                      "source": "user_guideline",
                      "type": "project_guideline"
                    }
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EMBEDDING GENERATION                                  â”‚
â”‚  Model: sentence-transformers/all-MiniLM-L6-v2                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                generate_embeddings(chunks)
                                â”‚
            For each chunk text, create 384-dimensional vector
                                â”‚
            Example:
            "Use type hints for all functions" â†’
            [0.123, -0.456, 0.789, ..., 0.234]  (384 floats)
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHROMADB STORAGE                                      â”‚
â”‚  Location: ./chroma_db/                                                 â”‚
â”‚  Collection: project_guidelines                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        guidelines_collection.upsert(
            embeddings=[vector1, vector2, vector3, ...],
            documents=["chunk1", "chunk2", "chunk3", ...],
            metadatas=[meta1, meta2, meta3, ...],
            ids=["owner_repo_file_0", "owner_repo_file_1", ...]
        )
                                â”‚
                    âœ… STORAGE COMPLETE
                                â”‚
                                â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                â”‚
                    USER STARTS CODE REVIEW
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WORKFLOW ORCHESTRATION                                â”‚
â”‚  Location: agent_orchestration.py                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        workflow.invoke(state)
                                â”‚
        Execution Flow:
        1. pr_fetcher_agent â†’ Fetch PR files from GitHub
        2. code_review_agent â†’ Review code (RAG USED HERE)
        3. test_coverage_agent â†’ Check test coverage
        4. doc_summarizer_agent â†’ Generate summary
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CODE REVIEW AGENT (RAG RETRIEVAL)                     â”‚
â”‚  Location: agents/code_review_agent.py (lines 306-365)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        For each file in PR:
            1. Detect language (Python, Java, JS, etc.)
            2. Extract code patch from PR diff
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG RETRIEVER - QUERY BUILDING                        â”‚
â”‚  Location: agents/rag_retriever.py                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        retriever = get_rag_retriever()
        project_name = state.project_name  # "owner/repo"
                                â”‚
        Build search query:
        query = f"{language} code review: {patch[:500]}"
        Example: "Python code review: def process_data(df): ..."
                                â”‚
        retriever.get_relevant_context(
            code_snippet=patch[:500],
            language="Python",
            project_name="cuongnln0812/pullpal-ai-agent",
            max_rules=5,
            max_guidelines=3
        )
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                       â–¼
        Search Review Rules         Search Project Guidelines
        (Global best practices)     (User-uploaded docs)
                    â”‚                       â”‚
                    â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VECTOR SIMILARITY SEARCH                              â”‚
â”‚  ChromaDB Collections:                                                  â”‚
â”‚  - review_rules (global coding standards)                               â”‚
â”‚  - project_guidelines (user-uploaded guidelines)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        Step 1: Convert query to embedding
        query_embedding = encoder.encode(query)
        â†’ [0.234, -0.567, 0.891, ..., 0.123]  (384 floats)
                                â”‚
        Step 2: Search in review_rules collection
        results = rules_collection.query(
            query_embeddings=[query_embedding],
            n_results=5
        )
        Returns top 5 most similar rules based on cosine similarity
                                â”‚
        Example Results:
        - Rule 1: "Use type hints" (distance: 0.23)
        - Rule 2: "Handle exceptions" (distance: 0.34)
        - Rule 3: "Avoid global variables" (distance: 0.45)
                                â”‚
                                â–¼
        Step 3: Search in project_guidelines collection
        results = guidelines_collection.query(
            query_embeddings=[query_embedding],
            n_results=3,
            where={"project": "cuongnln0812/pullpal-ai-agent"}  â† FILTER BY PROJECT
        )
        Returns top 3 most similar guideline chunks for THIS PROJECT
                                â”‚
        Example Results:
        - Chunk 0: "Our Python code must use..." (distance: 0.19)
        - Chunk 1: "Error handling should follow..." (distance: 0.28)
        - Chunk 2: "Database queries must be..." (distance: 0.37)
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FORMAT CONTEXT FOR LLM                                â”‚
â”‚  Location: agents/rag_retriever.py (format_context_for_prompt)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        Format retrieved context into readable text:
                                â”‚
        Output:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ## ğŸ“‹ Relevant Review Rules (from RAG):     â”‚
        â”‚                                             â”‚
        â”‚ 1. **[R001]** (HIGH) Use Type Hints        â”‚
        â”‚    All function parameters and returns     â”‚
        â”‚    must have type annotations...           â”‚
        â”‚                                             â”‚
        â”‚ 2. **[R005]** (MEDIUM) Handle Exceptions   â”‚
        â”‚    Use specific exception types...         â”‚
        â”‚                                             â”‚
        â”‚ ## ğŸ“– Relevant Project Guidelines (RAG):    â”‚
        â”‚                                             â”‚
        â”‚ 1. From `coding_guidelines.md`:            â”‚
        â”‚    Our Python code must use type hints...  â”‚
        â”‚                                             â”‚
        â”‚ 2. From `coding_guidelines.md`:            â”‚
        â”‚    Error handling should follow our...     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    âœ… RAG CONTEXT READY
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BUILD COMPLETE LLM PROMPT                             â”‚
â”‚  Location: agents/code_review_agent.py (lines 340-365)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        Combine all context:
        1. Template from prompts/code_review_prompt.txt
        2. Language-specific best practices
        3. Global review rules (JSON)
        4. Extended rules (markdown)
        5. ğŸ†• RAG-retrieved context (rules + guidelines)
        6. Custom guidelines (if provided inline)
        7. Code patch from PR
                                â”‚
        Final Prompt Structure:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ You are a code reviewer. Review this code: â”‚
        â”‚                                             â”‚
        â”‚ **Language:** Python                        â”‚
        â”‚                                             â”‚
        â”‚ **Best Practices:**                         â”‚
        â”‚ - Follow PEP 8                             â”‚
        â”‚ - Use type hints                           â”‚
        â”‚ ...                                        â”‚
        â”‚                                             â”‚
        â”‚ **Global Rules:**                           â”‚
        â”‚ - [R001] Use Type Hints                    â”‚
        â”‚ - [R002] Handle Errors                     â”‚
        â”‚ ...                                        â”‚
        â”‚                                             â”‚
        â”‚ ğŸ†• **RAG Retrieved Context:**              â”‚
        â”‚ [Formatted rules + guidelines from DB]     â”‚
        â”‚                                             â”‚
        â”‚ **Code to Review:**                         â”‚
        â”‚ ```python                                  â”‚
        â”‚ def process_data(df):                      â”‚
        â”‚     result = df.filter(...)                â”‚
        â”‚ ```                                        â”‚
        â”‚                                             â”‚
        â”‚ Return JSON array of issues...             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEND TO LLM (OpenAI/Anthropic)                        â”‚
â”‚  Location: agents/llm_client.py                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        response = client.invoke([HumanMessage(content=prompt)])
                                â”‚
        LLM processes:
        - Code patch
        - All best practices
        - RAG-retrieved relevant rules/guidelines
        - Project context
                                â”‚
                                â–¼
        LLM returns JSON:
        [
          {
            "type": "bug",
            "message": "Missing type hint for parameter 'df'",
            "suggestion": "Add type hint: def process_data(df: pd.DataFrame)",
            "line_start": 5,
            "code_snippet": "def process_data(df):"
          },
          {
            "type": "style",
            "message": "Function lacks docstring",
            "suggestion": "Add docstring explaining parameters and return",
            "line_start": 5
          }
        ]
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PARSE & ENHANCE LLM RESPONSE                          â”‚
â”‚  Location: agents/code_review_agent.py (safe_parse_json)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        1. Parse JSON response
        2. Extract code context from patch
        3. Add line numbers if missing
        4. Add code snippets if missing
        5. Group issues by file
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UPDATE STATE WITH FINDINGS                            â”‚
â”‚  Location: agents/code_review_agent.py (return statement)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        state.findings = [
          {
            "filename": "src/data_processor.py",
            "issues": [
              {
                "type": "bug",
                "message": "Missing type hint...",
                "suggestion": "Add type hint...",
                "line_start": 5,
                "code_snippet": "def process_data(df):"
              }
            ]
          }
        ]
                                â”‚
                    Return state to workflow
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WORKFLOW CONTINUES                                    â”‚
â”‚  Next Steps: test_coverage_agent â†’ doc_summarizer_agent                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DISPLAY RESULTS IN UI                                 â”‚
â”‚  Location: ui.py (lines 95-150)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        Show findings with:
        - File name
        - Issue type (bug/security/performance/style)
        - Line numbers
        - Code snippets
        - Issue message
        - Suggestions (influenced by RAG context!)
                                â”‚
                    âœ… REVIEW COMPLETE

```

---

## ğŸ“‹ Detailed Step-by-Step Flow

### Phase 1: File Upload & Storage

#### Step 1: User Input (ui.py lines 29-32)
```python
guideline_file = st.file_uploader(
    "Upload project coding guideline / rules (optional, .md, .txt, .json)",
    type=["md", "txt", "json"]
)
```
- **Input**: User selects a file from their computer
- **Supported formats**: Markdown (.md), text (.txt), JSON (.json)
- **Example file**: `coding_guidelines.md`

#### Step 2: Parse PR URL (ui.py lines 40-46)
```python
pr_info = parse_github_pr_url(pr_url)
# Returns: {"owner": "cuongnln0812", "repo": "pullpal-ai-agent", "pr_number": 123}

project_name = f"{pr_info['owner']}/{pr_info['repo']}"
# Result: "cuongnln0812/pullpal-ai-agent"
```
- **Purpose**: Extract owner and repo name to identify the project
- **Format**: `"owner/repo"` ensures unique project identification

#### Step 3: Read File Content (ui.py lines 48-51)
```python
guideline_bytes = guideline_file.getvalue()
guideline_content = guideline_bytes.decode("utf-8", errors="ignore")
```
- **Action**: Read binary file data and convert to UTF-8 text
- **Error handling**: Ignores invalid UTF-8 characters

#### Step 4: Store in Vector Database (ui.py lines 55-62)
```python
from agents.vector_store import get_vector_store
vector_store = get_vector_store()

vector_store.store_project_guidelines(
    content=guideline_content,
    filename=guideline_file.name,
    project_name=f"{pr_info['owner']}/{pr_info['repo']}"
)
```
- **Singleton pattern**: `get_vector_store()` returns same instance
- **Parameters**:
  - `content`: Full text of the guideline file
  - `filename`: Original filename (e.g., "coding_guidelines.md")
  - `project_name`: Full project path (e.g., "cuongnln0812/pullpal-ai-agent")

---

### Phase 2: Text Chunking & Embedding

#### Step 5: Extract Owner (vector_store.py lines 127-130)
```python
owner = None
if "/" in project_name:
    parts = project_name.split("/", 1)
    owner = parts[0]  # "cuongnln0812"
```
- **Purpose**: Extract GitHub username for flexible filtering
- **Result**: Owner stored separately from project name

#### Step 6: Chunk Text (vector_store.py lines 133, 249-276)
```python
chunks = self._chunk_text(content, chunk_size=500)

def _chunk_text(self, text: str, chunk_size: int = 500) -> List[str]:
    paragraphs = text.split('\n\n')  # Split by double newlines
    
    chunks = []
    current_chunk = ""
    
    for para in paragraphs:
        if len(current_chunk) + len(para) > chunk_size and current_chunk:
            chunks.append(current_chunk)
            current_chunk = para
        else:
            current_chunk += ("\n\n" if current_chunk else "") + para
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks
```

**Example**:
Input file (1500 chars):
```
# Python Coding Guidelines

## Type Hints
All functions must have type hints for parameters and return values.
This improves code readability and catches type errors early.
[... 450 characters ...]

## Error Handling
Always use specific exception types instead of bare except.
Log errors appropriately using the logging module.
[... 380 characters ...]

## Database Access
All database queries must use parameterized statements.
Never concatenate user input into SQL strings.
[... 420 characters ...]
```

Output chunks:
```python
[
    "# Python Coding Guidelines\n\n## Type Hints\nAll functions must...",  # 450 chars
    "## Error Handling\nAlways use specific exception types...",            # 380 chars
    "## Database Access\nAll database queries must use..."                  # 420 chars
]
```

#### Step 7: Build Metadata (vector_store.py lines 135-154)
```python
for idx, chunk in enumerate(chunks):
    metadata = {
        "filename": filename,              # "coding_guidelines.md"
        "project": project_name,           # "cuongnln0812/pullpal-ai-agent"
        "chunk_index": idx,                # 0, 1, 2, ...
        "source": "user_guideline",        # Identifies source type
        "type": "project_guideline"        # Collection type
    }
    if owner:
        metadata["owner"] = owner          # "cuongnln0812"
    
    metadatas.append(metadata)
    
    # Sanitize ID (replace "/" with "_")
    safe_project_name = project_name.replace("/", "_")
    ids.append(f"{safe_project_name}_{filename}_{idx}")
```

**Result**:
```python
metadatas = [
    {
        "filename": "coding_guidelines.md",
        "project": "cuongnln0812/pullpal-ai-agent",
        "owner": "cuongnln0812",
        "chunk_index": 0,
        "source": "user_guideline",
        "type": "project_guideline"
    },
    # ... more chunks
]

ids = [
    "cuongnln0812_pullpal-ai-agent_coding_guidelines.md_0",
    "cuongnln0812_pullpal-ai-agent_coding_guidelines.md_1",
    "cuongnln0812_pullpal-ai-agent_coding_guidelines.md_2"
]
```

#### Step 8: Generate Embeddings (vector_store.py lines 60-68, 163)
```python
embeddings = self.generate_embeddings(documents)

def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
    embeddings = self.encoder.encode(texts, show_progress_bar=False)
    return embeddings.tolist()
```

**Technical Details**:
- **Model**: `sentence-transformers/all-MiniLM-L6-v2`
- **Input**: List of text chunks
- **Output**: List of 384-dimensional vectors
- **Process**: 
  1. Tokenize text (split into words/subwords)
  2. Pass through transformer neural network
  3. Pool token embeddings into single sentence embedding
  4. Normalize to unit length

**Example**:
```python
Input:  "All functions must have type hints for parameters and return values"
Output: [0.123, -0.456, 0.789, 0.234, -0.567, ..., 0.891]  # 384 floats

Semantic meaning encoded in vector space:
- Similar concepts have similar vectors (high cosine similarity)
- "type hints" and "type annotations" â†’ close vectors
- "type hints" and "database queries" â†’ distant vectors
```

#### Step 9: Store in ChromaDB (vector_store.py lines 165-171)
```python
self.guidelines_collection.upsert(
    embeddings=embeddings,      # List of 384-dim vectors
    documents=documents,         # Original text chunks
    metadatas=metadatas,        # Project/file/owner info
    ids=ids                      # Unique identifiers
)
```

**ChromaDB Storage Structure**:
```
./chroma_db/
â”œâ”€â”€ chroma.sqlite3           # SQLite database with metadata
â””â”€â”€ [collection data]        # Vector indices and embeddings

Collection: project_guidelines
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID: cuongnln0812_pullpal-ai-agent_coding_guidelines.md_0        â”‚
â”‚ Embedding: [0.123, -0.456, ..., 0.891]  (384 floats)           â”‚
â”‚ Document: "# Python Coding Guidelines\n\n## Type Hints..."     â”‚
â”‚ Metadata: {                                                      â”‚
â”‚   "filename": "coding_guidelines.md",                           â”‚
â”‚   "project": "cuongnln0812/pullpal-ai-agent",                  â”‚
â”‚   "owner": "cuongnln0812",                                      â”‚
â”‚   "chunk_index": 0                                              â”‚
â”‚ }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

âœ… **Storage Complete**: Guidelines are now searchable by semantic similarity

---

### Phase 3: Code Review & RAG Retrieval

#### Step 10: Workflow Invocation (agent_orchestration.py lines 16-21)
```python
workflow.invoke(state)

# Workflow execution order:
# 1. pr_fetcher_agent    â†’ Fetch PR files from GitHub API
# 2. code_review_agent   â†’ Review code with RAG â† WE ARE HERE
# 3. test_coverage_agent â†’ Check test coverage
# 4. doc_summarizer_agent â†’ Generate PR summary
```

#### Step 11: Code Review Agent Initialization (code_review_agent.py lines 289-320)
```python
def code_review_agent(state: CodeReviewAgentState) -> CodeReviewAgentState:
    findings = []
    
    for f in state.files:  # Each file changed in PR
        filename = f["filename"]        # e.g., "src/data_processor.py"
        patch = f.get("patch", "")      # Git diff content
        
        # Detect language
        language = get_file_language(filename)  # "Python"
```

**PR File Structure**:
```python
state.files = [
    {
        "filename": "src/data_processor.py",
        "status": "modified",
        "additions": 15,
        "deletions": 3,
        "patch": """
@@ -15,7 +15,8 @@ import pandas as pd
 
-def process_data(df):
+def process_data(df: pd.DataFrame) -> pd.DataFrame:
+    \"\"\"Process dataframe and return cleaned version.\"\"\"
     result = df.filter(...)
     return result
"""
    }
]
```

#### Step 12: RAG Context Retrieval (code_review_agent.py lines 306-342)
```python
if RAG_ENABLED:
    retriever = get_rag_retriever()
    project_name = getattr(state, "project_name", None)  # "owner/repo"
    
    # Get relevant context
    context = retriever.get_relevant_context(
        code_snippet=patch[:500],    # First 500 chars of code
        language=language,           # "Python"
        project_name=project_name,   # "cuongnln0812/pullpal-ai-agent"
        max_rules=5,                 # Top 5 global rules
        max_guidelines=3             # Top 3 project guidelines
    )
    
    # Format for prompt
    rag_context = retriever.format_context_for_prompt(context)
```

#### Step 13: Build Search Query (rag_retriever.py lines 18-37)
```python
def get_relevant_context(self, code_snippet: str, language: str, 
                        project_name: Optional[str] = None,
                        max_rules: int = 5,
                        max_guidelines: int = 3) -> Dict[str, Any]:
    
    # Build search query combining code and language
    query = f"{language} code review: {code_snippet}"
```

**Example Query**:
```python
query = """Python code review: @@ -15,7 +15,8 @@ import pandas as pd

def process_data(df: pd.DataFrame) -> pd.DataFrame:
    \"\"\"Process dataframe and return cleaned version.\"\"\"
    result = df.filter(lambda x: x['status'] == 'active')
    return result"""
```

#### Step 14: Vector Similarity Search (rag_retriever.py lines 28-46)

**Part A: Search Review Rules**
```python
relevant_rules = self.vector_store.search_relevant_rules(
    query=query,
    n_results=5
)
```

**Implementation** (vector_store.py lines 173-200):
```python
def search_relevant_rules(self, query: str, n_results: int = 5):
    # Convert query to embedding vector
    query_embedding = self.generate_embeddings([query])[0]
    # Result: [0.234, -0.567, 0.891, ..., 0.123]  (384 floats)
    
    # Search ChromaDB
    results = self.rules_collection.query(
        query_embeddings=[query_embedding],
        n_results=5
    )
```

**ChromaDB Search Process**:
1. **Calculate cosine similarity** between query vector and all stored rule vectors
2. **Rank by similarity** (lower distance = more similar)
3. **Return top 5** most relevant rules

**Example Results**:
```python
relevant_rules = [
    {
        "content": "Use type hints. All function parameters and return values...",
        "metadata": {
            "rule_id": "R001",
            "title": "Type Hints Required",
            "severity": "high"
        },
        "distance": 0.19  â† Very similar to query!
    },
    {
        "content": "Add docstrings. All functions must have docstrings...",
        "metadata": {"rule_id": "R003", "severity": "medium"},
        "distance": 0.28
    },
    {
        "content": "Handle exceptions. Use specific exception types...",
        "metadata": {"rule_id": "R005", "severity": "high"},
        "distance": 0.45
    }
]
```

**Part B: Search Project Guidelines**
```python
relevant_guidelines = self.vector_store.search_project_guidelines(
    query=query,
    project_name=project_name,  # "cuongnln0812/pullpal-ai-agent"
    n_results=3
)
```

**Implementation** (vector_store.py lines 202-237):
```python
def search_project_guidelines(self, query: str, project_name: Optional[str] = None,
                              owner: Optional[str] = None, n_results: int = 3):
    query_embedding = self.generate_embeddings([query])[0]
    
    # Build filter
    where = None
    if project_name:
        where = {"project": project_name}  â† Filter by exact project match
    
    # Search with filter
    results = self.guidelines_collection.query(
        query_embeddings=[query_embedding],
        n_results=3,
        where=where  # Only return guidelines for THIS project
    )
```

**Key Feature**: Project filtering ensures each project's guidelines are isolated
- Project A uploads "Use tabs for indentation"
- Project B uploads "Use spaces for indentation"
- Each project only sees their own guidelines âœ…

**Example Results**:
```python
relevant_guidelines = [
    {
        "content": "Our Python code must use type hints for all...",
        "metadata": {
            "filename": "coding_guidelines.md",
            "project": "cuongnln0812/pullpal-ai-agent",
            "owner": "cuongnln0812",
            "chunk_index": 0
        },
        "distance": 0.15  â† Highly relevant!
    },
    {
        "content": "DataFrame processing should always validate input...",
        "metadata": {"filename": "coding_guidelines.md", "chunk_index": 2},
        "distance": 0.23
    }
]
```

#### Step 15: Format Context for LLM (rag_retriever.py lines 52-82)
```python
def format_context_for_prompt(self, context: Dict[str, Any]) -> str:
    sections = []
    
    # Format relevant rules
    if context.get("rules"):
        sections.append("## ğŸ“‹ Relevant Review Rules (from RAG):\n")
        for i, rule in enumerate(context["rules"], 1):
            meta = rule["metadata"]
            sections.append(
                f"{i}. **[{meta.get('rule_id', 'R?')}]** ({meta.get('severity', 'info').upper()}) "
                f"{meta.get('title', 'Rule')}\n"
                f"   {rule['content']}\n"
            )
    
    # Format relevant guidelines
    if context.get("guidelines"):
        sections.append("\n## ğŸ“– Relevant Project Guidelines (from RAG):\n")
        for i, guideline in enumerate(context["guidelines"], 1):
            meta = guideline["metadata"]
            sections.append(
                f"{i}. From `{meta.get('filename', 'unknown')}` "
                f"(project: {meta.get('project', 'unknown')}):\n"
                f"   {guideline['content'][:300]}{'...' if len(guideline['content']) > 300 else ''}\n"
            )
    
    return "\n".join(sections)
```

**Formatted Output**:
```markdown
## ğŸ“‹ Relevant Review Rules (from RAG):

1. **[R001]** (HIGH) Type Hints Required
   Use type hints. All function parameters and return values must have type annotations. This improves code readability and catches type errors early.

2. **[R003]** (MEDIUM) Docstrings Required
   Add docstrings. All functions must have docstrings explaining parameters, return values, and purpose.

## ğŸ“– Relevant Project Guidelines (from RAG):

1. From `coding_guidelines.md` (project: cuongnln0812/pullpal-ai-agent):
   Our Python code must use type hints for all functions. The type hints should follow PEP 484 standards and use built-in generic types when possible...

2. From `coding_guidelines.md` (project: cuongnln0812/pullpal-ai-agent):
   DataFrame processing should always validate input schemas before processing. Use assert statements or raise ValueError for invalid inputs...
```

#### Step 16: Build Complete LLM Prompt (code_review_agent.py lines 344-357)
```python
# Build the complete prompt using the template
prompt = PROMPT_TEMPLATE.format(
    filename=filename,
    language=language,
    best_practices_text=best_practices_text + extended_rules_text + global_rules_text + ("\n\n" + rag_context if rag_context else ""),
    custom_guidelines_section=custom_guidelines_section,
    patch=patch
)
```

**Complete Prompt Structure**:
```markdown
You are an expert code reviewer. Review the following code changes from a GitHub Pull Request.

**File:** src/data_processor.py
**Language:** Python

**Best Practices for Python:**
- Follow PEP 8 style guidelines
- Use type hints for function parameters and return values
- Use context managers (with statements) for resource management
- Prefer list comprehensions over map/filter for readability
- Use logging instead of print statements
- Handle exceptions appropriately, avoid bare except

**Extended Best Practices:**
[Content from extended_rules.md - 3544 characters]

**Global Review Rules:**
- **[R001]** (HIGH) Type Hints Required
  - All functions must have type hints
  - Fix: Add type annotations to all parameters and return values
- **[R002]** (HIGH) Error Handling
  - Never use bare except
  - Fix: Use specific exception types

## ğŸ“‹ Relevant Review Rules (from RAG):  â† RAG CONTEXT INJECTED HERE

1. **[R001]** (HIGH) Type Hints Required
   Use type hints. All function parameters and return values must have type annotations...

2. **[R003]** (MEDIUM) Docstrings Required
   Add docstrings. All functions must have docstrings...

## ğŸ“– Relevant Project Guidelines (from RAG):  â† PROJECT-SPECIFIC CONTEXT

1. From `coding_guidelines.md` (project: cuongnln0812/pullpal-ai-agent):
   Our Python code must use type hints for all functions. The type hints should...

2. From `coding_guidelines.md` (project: cuongnln0812/pullpal-ai-agent):
   DataFrame processing should always validate input schemas before processing...

**Custom Project Guidelines:**
[Any inline guidelines provided by user]

**Code Changes (Git Diff):**
```diff
@@ -15,7 +15,8 @@ import pandas as pd
 
-def process_data(df):
+def process_data(df: pd.DataFrame) -> pd.DataFrame:
+    """Process dataframe and return cleaned version."""
     result = df.filter(lambda x: x['status'] == 'active')
     return result
```

**Instructions:**
Analyze the code changes and return a JSON array of issues found. Each issue should have:
- type: "bug", "security", "performance", or "style"
- message: Description of the issue
- suggestion: How to fix it
- line_start: Starting line number
- line_end: Ending line number (optional)
- code_snippet: The problematic code (optional)

Return ONLY the JSON array, no additional text.
```

**Key Point**: The LLM now has:
- âœ… General Python best practices
- âœ… Global coding rules
- âœ… **RAG-retrieved relevant rules** (semantic search)
- âœ… **RAG-retrieved project-specific guidelines** (filtered by project)
- âœ… The actual code to review

#### Step 17: Send to LLM (code_review_agent.py lines 359-361)
```python
response = client.invoke([HumanMessage(content=prompt)])
llm_output = response.content
```

**LLM Processing**:
1. Reads all context (best practices + RAG context + code)
2. Identifies issues based on the combined knowledge
3. Returns structured JSON response

**LLM Response**:
```json
[
  {
    "type": "style",
    "message": "Docstring added but could be more detailed",
    "suggestion": "Expand docstring to include parameter descriptions and return value details as per project guidelines",
    "line_start": 17,
    "line_end": 18,
    "code_snippet": "def process_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Process dataframe and return cleaned version.\"\"\""
  },
  {
    "type": "bug",
    "message": "Lambda function in filter may raise KeyError",
    "suggestion": "Add input validation before filtering as per project guideline: 'DataFrame processing should always validate input schemas'",
    "line_start": 19,
    "code_snippet": "result = df.filter(lambda x: x['status'] == 'active')"
  }
]
```

**Notice**: The suggestions reference the RAG-retrieved project guidelines! ğŸ¯

#### Step 18: Parse & Enhance Response (code_review_agent.py lines 362-392)
```python
llm_issues = safe_parse_json(llm_output, filename)

# Extract code context
code_blocks = extract_code_context(patch)
sections = group_code_by_context(code_blocks)

# Enhance issues with line numbers and snippets
for issue in llm_issues:
    if "filename" not in issue:
        issue["filename"] = filename
    
    if "code_snippet" not in issue or not issue["code_snippet"]:
        if sections:
            first_section = sections[0]
            issue["line_start"] = first_section["start_line"]
            issue["line_end"] = first_section["end_line"]
            issue["code_snippet"] = "\n".join(
                f"{line['code']}" for line in first_section["lines"]
            )
```

#### Step 19: Update State (code_review_agent.py lines 395-400)
```python
if file_findings:
    findings.append({
        "filename": filename,
        "issues": file_findings
    })

state.findings = findings
return state
```

---

### Phase 4: Display Results

#### Step 20: Render in Streamlit UI (ui.py lines 95-150)
```python
st.subheader("ğŸ“ Code Review Findings")
if result['findings']:
    for f in result['findings']:
        with st.expander(f"ğŸ“„ {f['filename']} ({len(f['issues'])} issue(s))"):
            for idx, issue in enumerate(f["issues"], 1):
                issue_type = issue['type'].upper()
                type_color = {
                    'BUG': 'ğŸ›',
                    'SECURITY': 'ğŸ”’',
                    'PERFORMANCE': 'âš¡',
                    'STYLE': 'ğŸ’…'
                }.get(issue_type, 'ğŸ“Œ')
                
                st.markdown(f"### {type_color} Issue #{idx}: {issue_type}")
                
                if 'line_start' in issue:
                    st.caption(f"ğŸ“ Line {issue['line_start']}")
                
                if 'code_snippet' in issue:
                    st.code(issue['code_snippet'], language="python")
                
                st.markdown(f"**Issue:** {issue['message']}")
                st.info(f"ğŸ’¡ **Suggestion:** {issue['suggestion']}")
```

**Final UI Output**:
```
ğŸ“ Code Review Findings

â–¼ ğŸ“„ src/data_processor.py (2 issues)

  ### ğŸ’… Issue #1: STYLE
  ğŸ“ Line 17
  
  Code:
  def process_data(df: pd.DataFrame) -> pd.DataFrame:
      """Process dataframe and return cleaned version."""
  
  Issue: Docstring added but could be more detailed
  
  ğŸ’¡ Suggestion: Expand docstring to include parameter descriptions 
  and return value details as per project guidelines
  
  ---
  
  ### ğŸ› Issue #2: BUG
  ğŸ“ Line 19
  
  Code:
  result = df.filter(lambda x: x['status'] == 'active')
  
  Issue: Lambda function in filter may raise KeyError
  
  ğŸ’¡ Suggestion: Add input validation before filtering as per 
  project guideline: 'DataFrame processing should always validate input schemas'
```

---

## ğŸ”‘ Key Components Summary

### 1. **Storage Layer** (vector_store.py)
- **Purpose**: Store and retrieve coding guidelines and rules
- **Technology**: ChromaDB (vector database) + Sentence Transformers (embeddings)
- **Collections**:
  - `review_rules`: Global best practices
  - `project_guidelines`: User-uploaded project-specific guidelines
- **Key Methods**:
  - `store_project_guidelines()`: Store guideline files with embeddings
  - `search_relevant_rules()`: Find relevant global rules
  - `search_project_guidelines()`: Find relevant project guidelines (filtered by project)

### 2. **Retrieval Layer** (rag_retriever.py)
- **Purpose**: Retrieve relevant context for code review
- **Key Methods**:
  - `get_relevant_context()`: Search both rules and guidelines
  - `format_context_for_prompt()`: Format results for LLM
- **Filtering**: Ensures each project only sees its own guidelines

### 3. **Review Layer** (code_review_agent.py)
- **Purpose**: Perform code review using LLM + RAG context
- **Process**:
  1. Detect file language
  2. Retrieve RAG context
  3. Build comprehensive prompt
  4. Send to LLM
  5. Parse and enhance results
- **RAG Integration**: Lines 306-342

### 4. **UI Layer** (ui.py)
- **Purpose**: User interface for file upload and result display
- **Storage Trigger**: Lines 55-66 (when user clicks review button)
- **Result Display**: Lines 95-150 (shows issues found)

---

## ğŸ“Š Data Flow Summary

```
USER FILE â†’ DECODE â†’ CHUNK â†’ EMBED â†’ STORE IN CHROMADB
                                            â†“
                                    [Vector Database]
                                            â†“
REVIEW CODE â†’ BUILD QUERY â†’ VECTOR SEARCH â†’ RETRIEVE CONTEXT
                                            â†“
                                  [RAG Context Retrieved]
                                            â†“
FORMAT CONTEXT â†’ BUILD PROMPT â†’ SEND TO LLM â†’ PARSE RESPONSE
                                            â†“
                                    [Code Review Issues]
                                            â†“
                                    DISPLAY IN UI
```

---

## ğŸ¯ RAG Benefits

1. **Semantic Search**: Finds relevant guidelines based on meaning, not keywords
   - Query: "How to handle database errors?"
   - Matches: "Database exceptions should be caught", "Use try-except for DB operations"

2. **Project Isolation**: Each project has its own guidelines
   - No cross-contamination between projects
   - Filtering by `project_name` ensures correct context

3. **Contextual Reviews**: LLM suggestions are informed by project-specific rules
   - Generic review: "Add error handling"
   - RAG-enhanced review: "Add error handling as per project guideline section 3.2"

4. **Scalable Knowledge**: Can store unlimited guidelines without prompt size limits
   - Only retrieves most relevant chunks (top 3)
   - No need to send entire guideline file to LLM

5. **Persistent Memory**: Guidelines stored once, used for all future reviews
   - Upload once, benefit forever
   - No need to re-upload for each PR

---

## ğŸ›  Technical Specifications

- **Embedding Model**: sentence-transformers/all-MiniLM-L6-v2
- **Vector Dimensions**: 384
- **Chunk Size**: ~500 characters
- **Search Results**: Top 5 rules + Top 3 guidelines
- **Similarity Metric**: Cosine similarity (via ChromaDB)
- **Database**: ChromaDB with persistent storage at `./chroma_db`
- **Supported File Types**: .md, .txt, .json
- **Encoding**: UTF-8 with error handling
